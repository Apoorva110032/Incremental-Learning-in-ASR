# -*- coding: utf-8 -*-
"""Finetune_Conformer_on_Random_Dataset.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1BAdOXd0JdxM4zYXQGcdmK98DzcpOhtYf
"""

!pip install nemo_toolkit['all']
!pip install hydra-core==1.1

import os
os.environ["CUDA_DEVICE_ORDER"] = "PCI_BUS_ID"
os.environ["CUDA_VISIBLE_DEVICES"] = "0"
from nemo.collections.asr.models.ctc_bpe_models import EncDecCTCModelBPE
from nemo.core.config import hydra_runner
from nemo.utils import logging
import omegaconf
from omegaconf import OmegaConf
from omegaconf import DictConfig
import pytorch_lightning as pl
from pytorch_lightning.callbacks import ModelCheckpoint
from pytorch_lightning.plugins import DDPPlugin
import sys
import logging

sys.argv = ['']
del sys

LANGUAGE = "slices"
path = 'drive/Othercomputers/My MacBook Pro/Google_Drive/Tiny DataSet'
manifest_dir = os.path.join(path, LANGUAGE)
train_manifest = f"{manifest_dir}/train/train.json"
dev_manifest = f"{manifest_dir}/dev/dev.json"
test_manifest = f"{manifest_dir}/test/test.json"

@hydra_runner(config_path=r"drive/MyDrive/Colab Notebooks/Sprinklr_Project1/conformer", config_name="conformer_ctc_bpe")
def func(cfg):
  cfg['model']['train_ds']['manifest_filepath'] = train_manifest
  cfg['model']['validation_ds']['manifest_filepath'] = dev_manifest
  cfg['model']['test_ds']['manifest_filepath'] = test_manifest
  print(cfg['model']['validation_ds']['manifest_filepath'])
  checkpoint_callback = ModelCheckpoint(dirpath='drive/Othercomputers/My MacBook Pro/Google_Drive/Tiny DataSet/', 
                                        save_last=True, save_top_k=20,
                                        filename='{epoch}-{val_wer:.2f}-{other_metric:.2f}',
                                        monitor="val_wer", every_n_epochs=10)
  checkpoint_path = None
  trainer = pl.Trainer(num_processes=1, max_epochs=1, callbacks=[checkpoint_callback], accelerator='cpu')
  asr_model = EncDecCTCModelBPE.from_pretrained(model_name="stt_en_conformer_ctc_large")
  asr_model._wer.log_prediction = True
  asr_model.set_trainer(trainer)
  param_config = DictConfig(cfg['model'])
  asr_model.setup_training_data(param_config.train_ds)
  asr_model.setup_multiple_validation_data(val_data_config=param_config.validation_ds)
  asr_model.setup_multiple_test_data(test_data_config=param_config.test_ds)
  asr_model.spec_augmentation = asr_model.from_config_dict(asr_model.cfg.spec_augment)
  asr_model.setup_optimization(DictConfig(cfg['model']['optim']))
  asr_model.encoder.unfreeze()
  asr_model.decoder.unfreeze()

  trainer.fit(asr_model, ckpt_path=checkpoint_path)
  checkpoint_callback.best_model_path
  checkpoint_callback.best_model_score
  trainer.save_checkpoint
   
  asr_model.save_to("drive/Othercomputers/My MacBook Pro/Google_Drive/Tiny DataSet/result.nemo")
  if hasattr(cfg.model, 'test_ds') and cfg.model.test_ds.manifest_filepath is not None and False:
      gpu = 1 if cfg.trainer.gpus != 0 else 0
      test_trainer = pl.Trainer(
          gpus=gpu,
          precision=trainer.precision,
          amp_level=trainer.accelerator_connector.amp_level,
          amp_backend=cfg.trainer.get("amp_backend", "native"),
      )
      if asr_model.prepare_test(test_trainer):
        test_trainer.test(asr_model, verbose=True)

func()

# Commented out IPython magic to ensure Python compatibility.
# %cd /content/

import numpy as np
asr_model = EncDecCTCModelBPE.restore_from("drive/MyDrive/Copy of result.nemo")

"""Creating a list of Paths"""

os.chdir('/content/drive/Othercomputers/My MacBook Pro/Google_Drive/Tiny DataSet/slices/test')
directory = 'recordings2'
manifest_dir_url = '/content/drive/Othercomputers/My MacBook Pro/Google_Drive/Tiny DataSet/slices/test/recordings2'
new_list_of_paths = []

for filename in os.listdir(directory):
    new_list_of_paths.append(f"{manifest_dir_url}/{filename}")
print(new_list_of_paths)

predictions = asr_model.transcribe(paths2audio_files=new_list_of_paths)
print(predictions)

"""Creating list of true statements"""

os.chdir('/content/drive/Othercomputers/My MacBook Pro/Google_Drive/Tiny DataSet/slices/test')
directory = 'recordings2'
manifest_dir_url = '/content/drive/Othercomputers/My MacBook Pro/Google_Drive/Tiny DataSet/slices/test/recordings2'
new_list_of_statements = []

m = {'0': "zero",
    '1': "one",
    '2': "two",
    '3': "three",
    '4': "four",
    '5': "five",
    '6': "six",
    '7': "seven",
    '8': "eight",
    '9': "nine"}

for filename in os.listdir(directory):
    new_list_of_statements.append(f"{m[filename[0]]}")
print(new_list_of_statements)

!pip install evaluate
!pip install jiwer

import evaluate
from evaluate import load
wer = load("wer")

"""WER using FineTuned Model"""

wer_score = wer.compute(predictions=predictions, references=new_list_of_statements)
print(wer_score)

pretrained_model = EncDecCTCModelBPE.from_pretrained(model_name="stt_en_conformer_ctc_large")

"""WER using Pre-trained model"""

pretrained_model_predictions = pretrained_model.transcribe(paths2audio_files=new_list_of_paths)
wer_score = wer.compute(predictions=pretrained_model_predictions, references=new_list_of_statements)
print(wer_score)