{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"ebkd.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"15W9YIquMkyVCmZaEixJXEOpb-ux49Qe1","authorship_tag":"ABX9TyOIK8nxhmzTH5NaaTM0Tf1n"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["!pip install nemo_toolkit['all']\n","!pip install hydra-core==1.1\n","!pip install import-ipynb"],"metadata":{"id":"sp6lyVpnB1h2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import sys\n","\n","from nemo.core.classes import Serialization, Typing, typecheck\n","from nemo.core.neural_types import LossType, NeuralType, LogprobsType, IntType"],"metadata":{"id":"cvPM6ATbCqLo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["sys.argv = ['']\n","del sys"],"metadata":{"id":"zz174XQvpUPv","executionInfo":{"status":"ok","timestamp":1656153713297,"user_tz":-330,"elapsed":7,"user":{"displayName":"Apoorva Aggarwal","userId":"06292853917120984205"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["_all_ = ['EBKDLoss']"],"metadata":{"id":"SEWZb4joCrAU","executionInfo":{"status":"ok","timestamp":1656153713298,"user_tz":-330,"elapsed":7,"user":{"displayName":"Apoorva Aggarwal","userId":"06292853917120984205"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["class EBKDLoss(Serialization, Typing, nn.CTCLoss):\n","    @property\n","    def input_types(self):\n","        \"\"\"Input types definitions for EBKDLoss.\n","        \"\"\"\n","        return {\n","            \"teacher_logits\": NeuralType(('B', 'T', 'D'), LogprobsType()),\n","            \"log_probs\": NeuralType(('B', 'T', 'D'), LogprobsType()),\n","            \"teacher_feature_map\": NeuralType(('B', 'T', 'D'), LogprobsType()),\n","            \"student_feature_map\": NeuralType(('B', 'T', 'D'), LogprobsType())\n","        }\n","\n","    @property\n","    def output_types(self):\n","        \"\"\"Output types definitions for EBKDLoss.\n","        loss:\n","            NeuralType(None)\n","        \"\"\"\n","        return {\"loss\": NeuralType(elements_type=LossType())}\n","\n","    def _init_(self, num_classes, zero_infinity=False, reduction='mean_batch'):\n","        # Don't forget to properly call base constructor\n","        self._blank = num_classes\n","        # Don't forget to properly call base constructor\n","        if reduction == 'mean_batch':\n","            ctc_reduction = 'none'\n","            self._apply_batch_mean = True\n","        elif reduction in ['sum', 'mean', 'none']:\n","            ctc_reduction = reduction\n","            self._apply_batch_mean = False\n","        super().__init__(blank=self._blank, reduction=ctc_reduction, zero_infinity=zero_infinity)\n","\n","    @typecheck\n","    def forward(self, teacher_logits, log_probs, teacher_feature_map, student_feature_map):\n","        # EBKD Loss\n","        # here we transpose/permute because we expect [B, T, D] while PyTorch assumes [T, B, D]\n","        log_probs = log_probs.transpose(1, 0)\n","        teacher_logits = teacher_logits.transpose(1, 0)\n","        teacher_feature_map = teacher_feature_map.transpose(1, 0)\n","        student_feature_map = student_feature_map.transpose(1, 0)\n","\n","        # teacher greedy prediction probability - 1D Tensor (row of length B)\n","        teacher_gpp = torch.prod(torch.max(teacher_logits, 2), 0)\n","        # student greedy prediction probability - 1D Tensor (row of length B)\n","        student_gpp = torch.prod(torch.max(log_probs, 2), 0)\n","\n","        teacher_importance_map = torch.autograd.grad(torch.log(teacher_gpp), teacher_feature_map, retain_graph=True)\n","        student_importance_map = torch.autograd.grad(torch.log(student_gpp), student_feature_map, retain_graph=True)\n","\n","        teacher_attention_map = torch.nn.ReLU(torch.mul(teacher_importance_map, teacher_feature_map))\n","        student_attention_map = torch.nn.ReLU(torch.mul(student_importance_map, student_feature_map))\n","\n","        # normalized teacher attention map\n","        teacher_norm = torch.norm(teacher_attention_map, 2)\n","        # normalized student attention map\n","        student_norm = torch.norm(student_attention_map, 2)\n","\n","        # loss (Row of length B)\n","        ebkd_loss = torch.sum(torch.norm(\n","            (teacher_attention_map / teacher_norm) - (student_attention_map / student_norm), \n","            2) / teacher_attention_map.shape[0], 0)\n","\n","        if self._apply_batch_mean:\n","            ebkd_loss = torch.mean(ebkd_loss)\n","        return ebkd_loss\n"],"metadata":{"id":"nhK_lenjCuK6","executionInfo":{"status":"ok","timestamp":1656153713298,"user_tz":-330,"elapsed":7,"user":{"displayName":"Apoorva Aggarwal","userId":"06292853917120984205"}}},"execution_count":5,"outputs":[]}]}