{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"totalLoss.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyM40YKGbG4zkBW50Vlpvtvc"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive/')"],"metadata":{"id":"3TfaNiOy9YGN","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1656153923302,"user_tz":-330,"elapsed":22403,"user":{"displayName":"Apoorva Aggarwal","userId":"06292853917120984205"}},"outputId":"d3fc1a27-4f64-40bf-bf16-1a299466100e"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive/\n"]}]},{"cell_type":"code","source":["!pip install nemo_toolkit['all']\n","!pip install hydra-core==1.1\n","!pip install import-ipynb"],"metadata":{"id":"WfGmmfzk85Ik"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%cd \"/content/drive/MyDrive/Colab Notebooks/Paper 1 Implementation\""],"metadata":{"id":"IslMqMGP9AL9","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1656154095460,"user_tz":-330,"elapsed":20,"user":{"displayName":"Apoorva Aggarwal","userId":"06292853917120984205"}},"outputId":"f6fbd188-774d-44e2-8e69-3fdc343c29c9"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Colab Notebooks/Paper 1 Implementation\n"]}]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","\n","import import_ipynb\n","%run rbkd.ipynb import RBKDLoss\n","%run ebkd.ipynb import EBKDLoss\n","from typing import Dict, Optional, Union\n","from omegaconf import DictConfig, ListConfig, OmegaConf, open_dict\n","from nemo.core.classes import Serialization, Typing, typecheck\n","from nemo.collections.asr.losses.ctc import CTCLoss\n","from nemo.utils import logging, model_utils\n","from nemo.core.neural_types import LossType, NeuralType, LogprobsType, LabelsType, LengthsType"],"metadata":{"id":"dVdX5Klk8Qxl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["_all_ = ['TotalLoss']"],"metadata":{"id":"MDotI81x-xeK","executionInfo":{"status":"ok","timestamp":1656154137078,"user_tz":-330,"elapsed":430,"user":{"displayName":"Apoorva Aggarwal","userId":"06292853917120984205"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","execution_count":6,"metadata":{"id":"fFPuT0Fy7Rge","executionInfo":{"status":"ok","timestamp":1656154138129,"user_tz":-330,"elapsed":433,"user":{"displayName":"Apoorva Aggarwal","userId":"06292853917120984205"}}},"outputs":[],"source":["class TotalLoss(CTCLoss):\n","\n","    @property\n","    def input_types(self):\n","        \"\"\"Input types definitions for TotalLoss.\n","        \"\"\"\n","        return {\n","            \"teacher_logits\": NeuralType(('B', 'T', 'D'), LogprobsType()),\n","            \"log_probs\": NeuralType(('B', 'T', 'D'), LogprobsType()),\n","            \"targets\": NeuralType(('B', 'T'), LabelsType()),\n","            \"input_lengths\": NeuralType(tuple('B'), LengthsType()),\n","            \"target_lengths\": NeuralType(tuple('B'), LengthsType()),\n","            \"teacher_feature_map\": NeuralType(('B', 'T', 'D'), LogprobsType()),\n","            \"student_feature_map\": NeuralType(('B', 'T', 'D'), LogprobsType())\n","        }\n","\n","    @property\n","    def output_types(self):\n","        \"\"\"Output types definitions for TotalLoss.\n","        loss:\n","            NeuralType(None)\n","        \"\"\"\n","        return {\"loss\": NeuralType(elements_type=LossType())}\n","\n","    def __init__(self, *args, **kwargs):\n","\n","        # Calling Parent Class to access its methods \n","        super().__init__(\n","            num_classes=kwargs.get(\"num_classes\"),\n","            zero_infinity=True,\n","            reduction=kwargs.get(\"reduction\", \"mean_batch\")\n","        )\n","\n","        # Hyperparameters\n","        self.gamma = kwargs.get(\"gamma\", 500)\n","        self.beta = kwargs.get(\"beta\", 0.03)\n","        self.temperature = kwargs.get(\"temperature\", 3)\n","\n","        # CTC Loss Object Creation\n","        self.CTCLoss = CTCLoss(\n","            num_classes=kwargs.get(\"num_classes\"),\n","            zero_infinity=True,\n","            reduction=kwargs.get(\"reduction\", \"mean_batch\"),\n","        )\n","\n","        # RBKD Loss Object Creation\n","        self.RBKDLoss = RBKDLoss(\n","            num_classes=kwargs.get(\"num_classes\"),\n","            zero_infinity=True,\n","            reduction=kwargs.get(\"reduction\", \"mean_batch\"),\n","            temperature=self.temperature\n","        )\n","\n","        # EBKD Loss Object Creation\n","        self.EBKDLoss = EBKDLoss(\n","            zero_infinity=True,\n","            reduction=kwargs.get(\"reduction\", \"mean_batch\"),\n","        )\n","\n","    @typecheck\n","    def forward(self, log_probs, targets, input_lengths, target_lengths,\n","                teacher_logits, teacher_feature_map, student_feature_map):\n","        \n","        # Calling methods of CTC Loss \n","        ctc_loss = self.CTCLoss(\n","            log_probs, targets, input_lengths, target_lengths\n","        )\n","\n","        # Calling methods of RBKD Loss\n","        rbkd_loss = self.RBKDLoss(\n","            teacher_logits, log_probs\n","        )\n","\n","        # Calling methods of EBKD Loss\n","        ebkd_loss = self.EBKDLoss(\n","            teacher_logits, log_probs, teacher_feature_map, student_feature_map\n","        )\n","\n","        # Returning Total Loss\n","        return ctc_loss + (self.beta * rbkd_loss) + (self.gamma * ebkd_loss)"]}]}